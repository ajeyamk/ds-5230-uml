{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Word Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q",
        "colab_type": "text"
      },
      "source": [
        "# 1. Loading Pre-Trained BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfUN_KolV-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "7cdb9b68-3ae1-4aee-ff97-c1882b1faeda"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TzbWVoyMWF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5517e3db-b167-4d7b-eee1-cee447485017"
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  print(\"Yay I got a free GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "  print(\"No GPU\")\n",
        "  device=torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yay I got a free GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJEnBJ3gHTsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XidVwqRgN0xs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "662a174c-5983-47f5-8b52-9a1760256839"
      },
      "source": [
        "##Establishing data connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kf6fJ_dQ_Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parse data\n",
        "import pandas as pd\n",
        "email= pd.read_csv(\"/content/drive/My Drive/UML_project/train-sent.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPPcczHaSPRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "86288b8e-c86d-4365-ac6d-b733444def5c"
      },
      "source": [
        "email.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>e_id</th>\n",
              "      <th>email_body</th>\n",
              "      <th>subject_line</th>\n",
              "      <th>user</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>_161.subject</td>\n",
              "      <td>Wade,   I understood your number one priority ...</td>\n",
              "      <td>For Wade</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>_251.subject</td>\n",
              "      <td>Will,   Here is a list of the top items we nee...</td>\n",
              "      <td>Priority List</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>_3.subject</td>\n",
              "      <td>Christy,   I read these points and they defini...</td>\n",
              "      <td>Talking points about California Gas market</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>_50.subject</td>\n",
              "      <td>Jed,   I understand you have been contacted re...</td>\n",
              "      <td>Enron</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>_500.subject</td>\n",
              "      <td>Griff,    Can you accomodate Dexter as we have...</td>\n",
              "      <td>NGI access to eol</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...     user\n",
              "0           0  ...  allen-p\n",
              "1           1  ...  allen-p\n",
              "2           2  ...  allen-p\n",
              "3           3  ...  allen-p\n",
              "4           4  ...  allen-p\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxvcHIHfbEL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "de110680-0e18-4086-d045-decb51d547e7"
      },
      "source": [
        "email.email_body.iloc[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Wade,   I understood your number one priority was to deal with your vehicle  situation. You need to take care of it this week. Lucy can't hold the  tenants to a standard (vehicles must be in running order with valid stickers)  if the staff doesn't live up to it. If you decide to buy a small truck and  you want to list me as an employer for credit purposes, I will vouch for your  income. Phillip\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyLVAZGIUt8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f406167-765a-4380-9e92-04c9b82b3499"
      },
      "source": [
        "input_ids= []\n",
        "lengths=[]\n",
        "for i in range(0,len(email.email_body)):\n",
        "  encoded_email=tokenizer.encode(\n",
        "                                  email.email_body.iloc[i], #Sentence to be encoded\n",
        "                                  add_special_tokens = True #Adding cls and sep tokens\n",
        "                                )\n",
        "  input_ids.append(encoded_email)\n",
        "  lengths.append(len(encoded_email))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1929 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1789 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2082 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1853 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4772 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Yx2fWffHfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2aa7d977-9388-417f-e5e4-70ced33a80f5"
      },
      "source": [
        "#Some descriptive stats for understanding the word length distributions\n",
        "import numpy as np\n",
        "print('Minimum length is', min(lengths))\n",
        "print('Maximum length is', max(lengths))\n",
        "print('Medium length is', np.median(lengths))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum length is 29\n",
            "Maximum length is 4774\n",
            "Medium length is 80.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b__cDfrAf7Cc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "893fc942-96f3-43fc-e349-f6819d3c447d"
      },
      "source": [
        "#A plot to visualise the distribution of comment length\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "lengths=[min(l,512) for l in lengths] # to get a better scale on x axis and to see the distribution better\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "sns.distplot(lengths,kde=False,rug=False)\n",
        "plt.xlabel('Comment Length')\n",
        "plt.ylabel(\"Comment count\")\n",
        "plt.title(\"Comment Length Distribution\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Comment Length Distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghc3gmigic1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ce5e4b2-bfa0-4a6d-c278-4199590e021a"
      },
      "source": [
        "num_truncated = lengths.count(512)\n",
        "num_sentences = len(lengths)\n",
        "per= (float(num_truncated / num_sentences)) *100\n",
        "print('{:,} of {:,} sentences {:,}% are longer than 512 in token length'.format(num_truncated,num_sentences,per))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "112 of 6,374 sentences 1.7571383746470035% are longer than 512 in token length\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ6q4v9ijdl0",
        "colab_type": "text"
      },
      "source": [
        "So I think we can disregard these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4fz-rIGszos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "786f9474-09ca-402e-a8dd-6a174db88779"
      },
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "model.output_hidden_states = True\n",
        "model.to(device)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfKjQSEnjSic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# A function to return embeddings given a text\n",
        "\n",
        "def give_daddy_embeddings(tokenizer,model,input):\n",
        "  max_len=512\n",
        "  \n",
        "  input_ids=tokenizer.encode(\n",
        "                             input,\n",
        "                             add_special_tokens = True,\n",
        "                             max_length = max_len,\n",
        "                             truncation = True\n",
        "                            )\n",
        "  \n",
        "  results= pad_sequences([input_ids], maxlen=max_len,dtype=\"long\",truncating =\"post\",padding=\"post\")\n",
        "  input_ids = results[0]\n",
        "  attn_masks = [int(i>0) for i in input_ids]\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attn_masks = torch.tensor(attn_masks)\n",
        "  input_ids = input_ids.unsqueeze(0)\n",
        "  attn_masks = attn_masks.unsqueeze(0)\n",
        "  model.eval()\n",
        "  input_ids = input_ids.to(device)\n",
        "  attn_masks = attn_masks.to(device)\n",
        "  model=model.to(device)\n",
        "  with torch.no_grad():\n",
        "\n",
        "    logits,c,encoded_layers = model(\n",
        "                                  input_ids=input_ids,\n",
        "                                  attention_mask = attn_masks\n",
        "                                 )\n",
        "  \n",
        "  layer_i = 12\n",
        "  batch_i=0\n",
        "  token_i=0\n",
        "\n",
        "  vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "  vec=vec.detach().cpu().numpy()\n",
        "\n",
        "  return(vec)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7U6nsA4wAwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df65f4a5-f248-418c-bc77-00ad8d2aa92f"
      },
      "source": [
        "input = email.iloc[0].email_body\n",
        "vec = give_daddy_embeddings(tokenizer,model,input)\n",
        "print(vec.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OI_eQhESZd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d5ea34e8-efdd-4f6a-e405-96415d2449b6"
      },
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "embeddings=[]\n",
        "row_num =0\n",
        "# email_body=email['email_body']\n",
        "\n",
        "for index , row in email.iterrows():\n",
        "  if row_num % 1000 == 0 and not row_num == 0:\n",
        "\n",
        "    elapsed =time.time() - t0\n",
        "\n",
        "    print('Comment {:,} processed in time {:,}'.format(row_num,elapsed))\n",
        "\n",
        "  vec=give_daddy_embeddings(tokenizer,model,row.email_body)\n",
        "\n",
        "  embeddings.append(vec)\n",
        "\n",
        "  row_num +=1\n",
        "  "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 1,000 processed in time 25.898441553115845\n",
            "Comment 2,000 processed in time 51.27464151382446\n",
            "Comment 3,000 processed in time 76.80334424972534\n",
            "Comment 4,000 processed in time 102.19052505493164\n",
            "Comment 5,000 processed in time 127.58167552947998\n",
            "Comment 6,000 processed in time 153.00922441482544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmhVYY3kWq6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0ad78bd-7e5e-484b-c62b-dd5699fa76af"
      },
      "source": [
        "vectors = np.stack(embeddings)\n",
        "vectors.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6374, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD39LFWllW2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}